{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536105fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44301319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#op.path.join is used to give the path of the image irrespective of the os\n",
    "#folder structure is given\n",
    "#os.listdir is used to get all of the files of a particular dir\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus=tf.config.experimental.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit gpu from utilizing all of the memory-when u take large data set\n",
    "#all gpus are taken-no of gpus -devices that are available can be collected and displayed\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    #tells tensorflow to limit the memory and not use up all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b01a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_dir,'oily'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aefee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts=['jpeg','jpg','bmp','png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "image_extensions = [\".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d498eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir,image_class)):\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c74748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir,image_class)):\n",
    "        image_path=os.path.join(data_dir,image_class,image)\n",
    "        try:\n",
    "            img=cv2.imread(image_path)\n",
    "            tip=imgdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print(\"Image not in ext list{}\".format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image {}\".format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(os.path.join('data','oily','1.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD OUT DATA SET\n",
    "#tensor flow has an api that helps u build data pipeline-scales large data set\n",
    "#makes stuff cleanes\n",
    "tf.data.Dataset??\n",
    "#lot of capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dee260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de482485",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tf.keras.utils.image_dataset_from_directory??\n",
    "#?? is for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pipeline builtin\n",
    "#labels and classes need not be built\n",
    "#resizing included\n",
    "data=tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe37050",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0079f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set is a generator\n",
    "#convert into numpy iterator\n",
    "data_iterator=data.as_numpy_iterator()\n",
    "#the above line allows us to access data from the pipeline on the go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2796b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator\n",
    "#loop through and pull data-in massive amts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acces pipeline\n",
    "batch=data_iterator.next()\n",
    "#now we get the data in the req part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8bd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch)\n",
    "#2 parts created to the data set\n",
    "#part 1-images\n",
    "#part2-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74222a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape\n",
    "#automatically reshapes the images to make it more compatable\n",
    "#batch size and all the others can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]\n",
    "#0 represents different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=4,figsize=(20,20))\n",
    "for idx,img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "#now we get 0-dry skin and 1-oily skin\n",
    "#batch[0] cantains images\n",
    "#batch[1] contains labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the images are in the values 0 to 255-rgb format\n",
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6490309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make our classifier better we need to make the rgb values as small as possible-faster\n",
    "#therefore divi by 255\n",
    "scaled=batch[0]/255\n",
    "#leaves values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING OF DATA\n",
    "#preprocess part1 - scaling\n",
    "#preprocess part2 - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddff1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling part\n",
    "#pipeling map fn apply transformation can be applied as our data is loaded to our pipeline\n",
    "#speeds up the process of accessing our data from the disc\n",
    "data = data.map(lambda x,y:(x/255,y))\n",
    "#data.map-trandsformation in pipeline\n",
    "#x-images and y-target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd62f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow data api helps in a ton functions across the data set\n",
    "#inside of our data pipeline\n",
    "scaled_iterator=data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38991189",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09381313",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator.next()[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting our data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b25373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll make train 70% of that data so the split ratio we'll make it 70:30\n",
    "#val is forvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(len(data)*.7)\n",
    "val_size=int(len(data)*.2)+1 #evaluation while training\n",
    "test_size=int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size+train_size+test_size#allocation of the data to various partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take and skip data from tensorflow\n",
    "#take defines how much data we take for each part\n",
    "#skip-avoids already taken part\n",
    "train=data.take(train_size)\n",
    "val=data.skip(train_size).take(val_size)\n",
    "test=data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)\n",
    "#shuffle the data by avoiding the already allocated batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEP LEARNING MODEL\n",
    "#ai part\n",
    "#Part 1-deep learning model-nn\n",
    "#Part 2-training the model \n",
    "#Part 3-consists of the performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building api from tensor flow we use sequential-quick and easy\n",
    "#this is very straightfroward that like with one data input and one data output\n",
    "#the alternate option being the functional api thats very powerful that takes in multiple inputs and gives multiple outputs\n",
    "#conv2d is the cnn spatial conveolution over pics\n",
    "#maxPooling-condensing layer\n",
    "#Dense-is fully connected layer\n",
    "#flatten the convolution that goes to kernels that give output\n",
    "#dropout not that useful for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced290f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture,add method is another\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is adding conv layer and maxPooling layer\n",
    "#first layer must be input layer\n",
    "#conv2d has 16 filters here it scans the images and extracts/condenses the info from the pictures inside it .\n",
    "#stride-1 here it goes pixel by pixel\n",
    "#3*3 isthe size of the filters\n",
    "#how we make architectural changes-model parameters changes decide the performance of the models\n",
    "#activation -relu output is passed to fn that makes output below 0 makes the values and positive values are preserved\n",
    "#sigmoid activation the outpus are modified by passing it to a graphical curve\n",
    "#changing the function makes the output \n",
    "#maxpooling takes a set of number 2*2 region it goes through reduces info by half\n",
    "\n",
    "model.add(Conv2D(16,(3,3),1,activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#next layers added\n",
    "\n",
    "model.add(Conv2D(32,(3,3),1,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16,(3,3),1,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#when we applu the conv layers the filters are gonna be the last channels-we dont want channel value we need 1 value as output\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected layers\n",
    "#final layer is 256 parts\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "\n",
    "#takes in a range of values and makes the vaue between 0 and 1 values.This is basically the output that we are expected to give\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "#0-dry and 1-oily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next most important part\n",
    "#optimizer-adam(there are many to choose from)\n",
    "#loss is for a binary classifier-accuracy is taken into consideration to check the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054769af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam',loss=tf.losses.BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary fow model transforms our data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable that points to logs folder\n",
    "logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback calls the pointed out place-logbacks to the models training\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and predict are important parts of thetraining models-\n",
    "#fit from training data-epochs no of parts on training parts\n",
    "#we could also see how its training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0902c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(train,epochs=20,validation_data=val,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu makes taining part fast-loss decreases and accuracy increases\n",
    "#we could also make the the model without using gpu's\n",
    "#later the hist value could be for sure used find the other logs\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a13c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history\n",
    "#loss and accuracy info can be optained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 3 -plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-training loss and val loss plotted\n",
    "fig=plt.figure()\n",
    "plt.plot(hist.history['loss'],color='teal',label='loss')\n",
    "plt.plot(hist.history['val_loss'],color='orange',label='val_loss')\n",
    "#fig.subtitle('Loss',fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val score needs to decrease-regularization needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy visualised\n",
    "fig=plt.figure()\n",
    "plt.plot(hist.history['accuracy'],color='teal',label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'],color='orange',label='val_accuracy')\n",
    "#fig.subtitle('Loss',fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now ths is our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2:EVALUATION OF PERFORMANCE\n",
    "#key metrics are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision,Recall,BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=Precision()\n",
    "re=Recall()\n",
    "acc=BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test them\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x,y=batch\n",
    "    yhat=model.predict(x)\n",
    "    pre.update_state(y,yhat)\n",
    "    re.update_state(y,yhat)\n",
    "    acc.update_state(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8962ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the values present th higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1608a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part2 Testing\n",
    "import cv2\n",
    "#open cv library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2385b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('dry.sample.jpg')\n",
    "#color correction\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de425a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resize before pushing it nn\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "resize=tf.image.resize(rgb_img,(256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092213ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1be7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(resize,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f369806",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3271b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encapsulation by putting it into the extradimen is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat>0.5:\n",
    "    print(f'Predicted class is Oily Skin')\n",
    "else:\n",
    "    print(f'Predicted class is Dry Skin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ec1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE MODEL THE FINAL!! PART\n",
    "#to make the model to be available to other developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1adad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','skinclassification.hdf5'))\n",
    "#serialization-load model can be used to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the model back up\n",
    "new_model=load_model(os.path.join('models','skinclassification.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatnew=new_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a26056",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhatnew>0.5:\n",
    "    print(\"oily skin\")\n",
    "else:\n",
    "    print(\"dry skin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039801e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f56cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# def greet(name):\n",
    "#     return \"Hello \" + name + \"!\"\n",
    "\n",
    "# demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch(show_api=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540757bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    img_3d=img.reshape(1, 256, 256, 3)\n",
    "    prediction=model.predict(img_3d)[0]\n",
    "    return {class_names[i]:float(prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(sepia, gr.Image(), \"image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49113c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=load_model(os.path.join('models','skinclassification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhatnew>0.5:\n",
    "    print(\"oily skin\")\n",
    "else:\n",
    "    print(\"dry skin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a968820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a01da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
